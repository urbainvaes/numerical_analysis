\documentclass[11pt]{article}
\usepackage{setspace}
\onehalfspacing
\usepackage{fontawesome}
\usepackage[outputdir=build,newfloat]{minted}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage[margin=1.2in]{geometry}
\usepackage{amsmath,amsthm,amssymb}
\usepackage{mathtools}
\theoremstyle{definition}
\newtheorem{question}{{\normalfont \faGears}~Question}
\newtheorem{compexercise}{{\normalfont \faLaptop}~Question}
\input{../macros.tex}
\begin{document}

\title{Numerical Analysis: Practice Midterm (30 marks)}
\author{Urbain Vaes}
\maketitle

\begin{question}
    [Floating point arithmetic, 10 marks]
    True or false? (+1/0/-1)
    \begin{enumerate}
        \item Let $(\placeholder)_2$ denote binary representation.
            It holds that
            \(
                (0.1111)_2 + (0.0001)_2 = 1.
            \)
        \item It holds that
            \(
                (1000)_{16} \times (0.001)_{16} = 1.
            \)
        \item It holds that
            \[
                (0.\overline{1})_3 = \frac{1}{2}.
            \]

        \item
            In base 16, all the natural numbers from 1 to 300 can be represented using 2 digits.

        \item
            If $x$ is finite \julia{Float64} number,
            then $x$ is a rational number.

        \item
            In Julia, \julia{eps(2.0)} returns the machine epsilon for the Float64 format.

        \item
            Storing the matrix obtained with the Julia command \julia{zeros(10^5, 10^5)} would require more than 50GB of memory.

        \item
            The spacing (in absolute value) between successive double-precision (\julia{Float64}) floating point numbers is constant.

        \item
            It holds that $(0.\overline{10101})_2 = (1.2345)_{10}$.

        \item Machine addition~$\madd$ is an associative operation.
            More precisely, given any three double-precision floating point numbers $x$, $y$ and $z$,
            the following equality holds:
            \[
                (x \madd y) \madd z = x \madd (y \madd z).
            \]
        \item
            The machine epsilon is the smallest strictly positive number that can be represented in a floating point format.

        \item
            In Julia, the command \julia{nextfloat(2.)} returns
            the next \julia{Float32} number after $2$.
    \end{enumerate}
\end{question}

\newpage
\begin{question}
    [Interpolation and approximation, 5 marks]
    Throughout this exercise, we use the notation
    $x^n_i = i/n$ and assume that $u \colon \real \to \real$ is a smooth function.
    The notation $\poly(n)$ denotes the set of polynomials of degree less than or equal to $n$.
    We proved in class that,
    for all $n \geq 0$,
    there exists a unique polynomial~$p_n \in \poly(n)$ such that
    \begin{equation}
        \label{eq:interpolation}
        \forall i \in \{0, \dotsc, n\}, \qquad
        p_n(x^n_i) = u (x^n_i).
    \end{equation}
    \begin{enumerate}
        \item
            The degree of $p_n$ is exactly~$n$ or $n - 1$.

        \item
            Suppose that $u \in \poly(m)$.
            Then~$u = p_n$ if~$n \geq m$.

        \item
            Fix $u(x) = \sin(3\pi x)$. Then $p_3(x) = 0$.

        \item
            Fix $u(x) = \cos(\pi x)$.
            Then $p_2(x) = (2x - 1)^2$.

        \item
            Suppose $u$ is smooth.
            Then it necessarily holds that
            \[
                \max_{x \in [0, 1]} \bigl\lvert u(x) - p_n(x) \bigr\rvert \xrightarrow[n \to \infty]{} 0.
            \]

        \item
            Fix $u(x) = \cos(2x)$.
            Then
            \[
                \max_{x \in [0, 1]} \bigl\lvert u(x) - p_n(x) \bigr\rvert \xrightarrow[n \to \infty]{} 0.
            \]

        \item
            Fix $u(x) = \sin(x)$.
            Then
            \[
                \max_{x \in \real} \bigl\lvert u(x) - p_n(x) \bigr\rvert \xrightarrow[n \to \infty]{} 0.
            \]

        \item
            Suppose that $p(x) \in \poly(n)$ and let $q(x) = p(x+1) - p(x)$. Then $q \in \poly(n-1)$.

        \item
            Let $(f_0, f_1, f_2, \dotsc) = (1, 1, 2, \dotsc)$ denote the Fibonacci sequence.
            There exists a polynomial~$p$ such that
            \begin{equation*}
                \label{eq:fibonacci_polynomial}
                \forall n \in \nat, \qquad
                f_n = p(n).
            \end{equation*}

        \item
            For any matrix $\mat A \in \real^{20 \times 10}$,
            the linear system
            \[
                \mat A^\t \mat A \vect \alpha = \mat A^\t \vect \alpha
            \]
            admits a unique solution.
    \end{enumerate}
\end{question}

\newpage
\begin{question}
    [Numerical integration, 5 marks]
    True or false? (+1/0/-1)
    \begin{enumerate}
        \item
            The degree of precision of the following rule is equal to 2:
            \[
                \int_{-1}^{1} u(x) \, \d x \approx 2u(0).
            \]

        \item
            The degree of precision of the following rule is equal to 3:
            \[
                \int_{-1}^{1} u(x) \, \d x \approx u \left(-\frac{1}{3}\right) + u \left(\frac{1}{3}\right).
            \]

        \item
            There exists a quadrature rule with a degree of precision equal to $2N + 1$ of the form
            \[
                \int_{-1}^{1} u(x) \, \d x \approx
                \sum_{n=0}^{N} w_n u(x_n).
            \]

        \item
            Legendre polynomials are orthogonal for the inner product
            \[
                \ip{f, g} := \int_{-1}^{1} f(x) \, g(x) \,  \d x.
            \]

        \item
            Fix $u(x) = \cos(x)$ and let
            \begin{equation}
                \label{eq:mc}
                I^{MC}_N = \frac{1}{N} \sum_{n=1}^{N} u(X_n), \qquad X_n \stackrel{\rm i.i.d.}{\sim} \mathcal U([0, 1]).
            \end{equation}
            The expectation of~$\widehat I_N$ is independent of~$N$.

        \item
            The variance of $I^{MC}_N$ in~\eqref{eq:mc} tends to 0 in the limit $N \to \infty$.

        \item
            Let $x^N_i = i/N$ and consider the following approximation of $\int_{0}^{1} u(x) \, \d x$:
            \begin{equation}
                \label{eq:trapezium}
                I^T_N = \frac{1}{2N} \Bigl( u\left(x^N_0\right) + 2 u\left(x^N_1\right) + 2 u\left(x^N_2\right) + \dotsc + u\left(x^N_{N-2}\right) + 2 u\left(x^N_{N-1}\right) + u\left(x^N_N\right) \Bigr)
            \end{equation}
            Fix $u(x) = (1 + 25 x^2)^{-1}$.
            Then $I^T_N$ diverges in the limit $N \to \infty$.

        \item
            Fix $u(x) = \cos(x)$ and let $I^T_N$ be as in~\eqref{eq:trapezium}.
            Then there exists $C \in (0, \infty)$ such that
            \[
                \forall N > 5, \qquad
                \left\lvert I^T_N - \int_{0}^1 u(x) \, \d x \right\rvert \leq \frac{C}{N^4}.
            \]

        \item
            Fix $u(x) = 2x - 1$ and let $I^T_N$ be as in~\eqref{eq:trapezium}.
            Then $I^T_N = 0$ for $N \geq 5$.
    \end{enumerate}
\end{question}

\newpage

\begin{compexercise}
    [Floating point arithmetic, 5 marks]
    Read the documentation of the \julia{nextfloat} function.
    Using this function,
    plot on the same graph the spacing between successive \julia{Float16}, \julia{Float32} and \julia{Float64} numbers in the range $[1, 10^6]$.
    Use a logarithmic scale for the $x$ axis.
    You may find it useful to use \julia{LinRange{Type}(a, b, n)}
    to create an array of $n$ equidistant numbers of type \julia{Type} between $a$ and $b$.
\end{compexercise}

\begin{compexercise}
    [Interpolation, 5 marks]
    Consider the data
    \[
        x =
        \begin{pmatrix}
            1 \\
            2 \\
            3 \\
        \end{pmatrix},
        \qquad
        y =
        \begin{pmatrix}
            1 \\
            5 \\
            7 \\
        \end{pmatrix}
    \]
    Find $\alpha_1, \alpha_2, \alpha_3$ such that
    \[
        \widehat u(x) := \alpha_1 \, \cos(\pi x) + \alpha_2 \, \sin(\pi x) + \alpha_3 \, 2^x
    \]
    satisfies
    \[
        \forall i \in \{1, 2, 3\}, \qquad
        \widehat u(x_i) = y_i.
    \]
    Plot on the same graph the functions $u$ and $\widehat u$.
\end{compexercise}

\newpage
\begin{compexercise}
    [Approximation, 10 marks]
    Write without using the \julia{Polynomials} library a Julia function \julia{approx(x, y, d, X)} to obtain,
    given data points
    \[
        (x_0, y_0), \dotsc, (x_N, y_N)
    \]
    and an positive integer $d \leq N$,
    the polynomial $p \in \poly(d)$ minimizing the distance
    \[
        \sum_{n=1}^{N} \bigl\lvert p(x_i) - u_i \bigr\rvert^2.
    \]
    Your function should return the values taken by~$p$
    when evaluated at the points $X_1, \dotsc, X_m$.
    Within the function, proceed in 3 steps
    \begin{itemize}
        \item
            First create the following matrix and vector:
            \[
                \mat A
                \begin{pmatrix}
                    1 & x_0 & \hdots & x_0^d \\
                    \vdots & \vdots & & \vdots \\
                    1 & x_{N} & \hdots & x_N^d
                \end{pmatrix},
                \qquad
                \vect b :=
                \begin{pmatrix}
                    u_0 \\
                    \vdots \\
                    u_d
                \end{pmatrix}.
            \]
            \item
                Then solve the normal equations using the backslash operator:
                \begin{equation}
                    \label{eq:normal_equations}
                    \mat A^\t \mat A \vect \alpha = \mat A^\t \vect b.
                \end{equation}

            \item
                Finally, evaluate the polynomial
                \[
                    p(x) = \alpha_0 + \alpha_1 x + \dotsc + \alpha_d x^d.
                \]
                at all the points in \julia{X} and return the result.
    \end{itemize}
    Use the following data,
    of the altitude of a marble as a function of time,
    to test your code.
    The experiment was performed on a different planet.
    Can you find which one?

    \begin{minted}{julia}
        import Plots
        function approx(x, y, d, X)
            # Your code comes here
        end
        # Time since dropping pen
        x = [0., 1., 2., 3., 4., 5.]
        # Altitude of pen
        y = [100., 98., 92., 83., 71., 55.]
        X = LinRange(0, 1, 200)
        Y = approx(x, y, 2, X)
        Plots.plot!(X, Y, label="Approximation")
        Plots.scatter!(x, y, label="Data")
    \end{minted}
\end{compexercise}

\newpage
\begin{compexercise}
    [Numerical integration]
    Milne's integration rule reads
    \[
        \int_{-1}^{1} u(x) \, \d x
        % \approx \frac{2}{3} \left( 2 f\left(-\frac{1}{2}\right) - f(0) + 2 f\left(\frac{1}{2}\right) \right)
        \approx w_1 f\left(-\frac{1}{2}\right) - w_2 f(0) + w_3 f\left(\frac{1}{2}\right).
    \]
    \begin{itemize}
        \item
            Write a function \julia{get_milne_weights} which calculates and returns a vector containing the weights~$w_1, w_2, w_3$.

        \item
            Write a function \julia{composite_milne(u, a, b, N)},
            which returns an approximation of the integral
            \[
                \int_{a}^{b} u(x) \, \d x
            \]
            obtained by partitioning the integration interval $[a, b]$ into $N$ cells,
            and applying Milne's rule quadrature within each cell.

        \item
            Take $u(x) = \cos(x)$, $a = -1$ and $b = 1$.
            Illustrate the evolution of the error for $N$ varying from 1 to 1000.

        \item
            Estimate the order of convergence with respect to $N$, i.e.\ find~$\alpha(n)$ such that
            \[
                \lvert \widehat I_{N} - I \rvert \propto C N^{-\alpha},
            \]
            where $I$ denotes the exact value of the Integral
            and $\widehat I_{N}$ denotes its approximation.
            In order to find~$\alpha$,
            use the function \julia{fit} from the \julia{Polynomials} package to find a linear approximation
            of the form
            \[
                \log \lvert \widehat I_{N} - I \rvert \approx C - \alpha \log(N).
            \]
    \end{itemize}
\end{compexercise}

\end{document}
